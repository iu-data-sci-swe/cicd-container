{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef35f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../data/fraud.csv.bz2')\n",
    "\n",
    "# Parse the time column as datetime\n",
    "df['time'] = pd.to_datetime(df['time'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Shape:\")\n",
    "print(df.shape)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b029ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup train / test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_cleaned = df.dropna().copy()\n",
    "\n",
    "X = df_cleaned.drop('fraud', axis=1)\n",
    "y = df_cleaned['fraud']\n",
    "\n",
    "# TODO stratify?\n",
    "# hard code random state for reproducibility (test later)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=566571358)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a10999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the train data\n",
    "\n",
    "print(X_train.shape)\n",
    "X_train.info()\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858c36c4",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4721187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X = X_train.copy()\n",
    "y = y_train.copy()\n",
    "\n",
    "# add hour of day as a feature\n",
    "X['hour'] = X['time'].dt.hour\n",
    "\n",
    "# Fit OneHotEncoders on training data\n",
    "enc_product = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "enc_gender = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "enc_state = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "enc_hour = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit and transform - reshape needed because OneHotEncoder expects 2D input\n",
    "product_encoded = enc_product.fit_transform(X[['product_category']])\n",
    "gender_encoded = enc_gender.fit_transform(X[['gender']])\n",
    "state_encoded = enc_state.fit_transform(X[['address_state']])\n",
    "hour_encoded = enc_hour.fit_transform(X[['hour']])\n",
    "\n",
    "# Get feature names for the encoded columns\n",
    "product_cols = enc_product.get_feature_names_out(['product_category'])\n",
    "gender_cols = enc_gender.get_feature_names_out(['gender'])\n",
    "state_cols = enc_state.get_feature_names_out(['address_state'])\n",
    "hour_cols = enc_hour.get_feature_names_out(['hour'])\n",
    "\n",
    "# Create DataFrames from encoded arrays\n",
    "product_df = pd.DataFrame(product_encoded, columns=product_cols, index=X.index)\n",
    "gender_df = pd.DataFrame(gender_encoded, columns=gender_cols, index=X.index)\n",
    "state_df = pd.DataFrame(state_encoded, columns=state_cols, index=X.index)\n",
    "hour_df = pd.DataFrame(hour_encoded, columns=hour_cols, index=X.index)\n",
    "\n",
    "# Drop original columns and concatenate encoded ones\n",
    "X = X.drop(['product_category', 'gender', 'address_state', 'time'], axis=1)\n",
    "# X = pd.concat([X, product_df, gender_df, state_df], axis=1) # everything\n",
    "X = pd.concat([hour_df, product_df, gender_df, X[\"amount\"].to_frame()], axis=1) # only hour, product_category, amount\n",
    "print(X.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8555828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance X/y: keep all True, sample smaller number of False\n",
    "pos_idx = y[y].index\n",
    "neg_idx = y[~y].sample(n=len(pos_idx)*4).index\n",
    "\n",
    "balanced_idx = pos_idx.union(neg_idx)\n",
    "X = X.loc[balanced_idx]\n",
    "y = y.loc[balanced_idx]\n",
    "\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc035708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup validation set\n",
    "X, X_valid, y, y_valid = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "print(X.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e060a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(max_iter=1000, class_weight=\"balanced\", verbose=1)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff7d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='poly', degree=2, C=.01, gamma=.01, class_weight='balanced', max_iter=100000000, verbose=True)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe91b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(hidden_layer_sizes=[10,10], learning_rate = \"adaptive\", tol=1e-6, max_iter=800, verbose=True)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aac70d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=20, class_weight='balanced', verbose=1)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231ec988",
   "metadata": {},
   "source": [
    "### Training Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54415fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# Get predictions on training data\n",
    "if True:\n",
    "  y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "  threshold = 0.3  # Set your custom threshold here\n",
    "  y_pred = y_pred_proba >= threshold\n",
    "else:\n",
    "  y_pred = model.predict(X)\n",
    "\n",
    "print(pd.crosstab(y, y_pred, rownames=['Actual'], colnames=['Predicted']))\n",
    "\n",
    "# Calculate metrics\n",
    "recall = recall_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eac7e3f",
   "metadata": {},
   "source": [
    "### Validation Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ca86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# Get predictions on validation data\n",
    "if True:\n",
    "  y_pred_proba = model.predict_proba(X_valid)[:, 1]\n",
    "  threshold = 0.1  # Set your custom threshold here\n",
    "  y_pred = y_pred_proba >= threshold\n",
    "else:\n",
    "  y_pred = model.predict(X_valid)\n",
    "\n",
    "print(pd.crosstab(y_valid, y_pred, rownames=['Actual'], colnames=['Predicted']))\n",
    "\n",
    "# Calculate metrics\n",
    "recall = recall_score(y_valid, y_pred)\n",
    "precision = precision_score(y_valid, y_pred)\n",
    "f1 = f1_score(y_valid, y_pred)\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfe2c76",
   "metadata": {},
   "source": [
    "## Store the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92259ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model and encoders\n",
    "with open('../model/model.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model': model,\n",
    "        'enc_product': enc_product,\n",
    "        'enc_hour': enc_hour,\n",
    "        'enc_gender': enc_gender,\n",
    "        'enc_state': enc_state,\n",
    "        'product_cols': product_cols,\n",
    "        'hour_cols': hour_cols,\n",
    "        'gender_cols': gender_cols,\n",
    "        'state_cols': state_cols,\n",
    "        'model_version': '0.1',\n",
    "        'train_date': pd.Timestamp.now().isoformat()\n",
    "    }, f)\n",
    "\n",
    "print(\"Model and encoders saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de88a05f",
   "metadata": {},
   "source": [
    "# Final Test on Withheld Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfc1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply encoding on Test Data\n",
    "X_final_test = X_test.copy()\n",
    "y_final_test = y_test.copy()\n",
    "\n",
    "# add hour of day as a feature\n",
    "X_final_test['hour'] = X_final_test['time'].dt.hour\n",
    "\n",
    "# Use already trained encoders!\n",
    "product_encoded = enc_product.transform(X_final_test[['product_category']])\n",
    "gender_encoded = enc_gender.transform(X_final_test[['gender']])\n",
    "state_encoded = enc_state.transform(X_final_test[['address_state']])\n",
    "hour_encoded = enc_hour.transform(X_final_test[['hour']])\n",
    "\n",
    "# Get feature names for the encoded columns\n",
    "product_cols = enc_product.get_feature_names_out(['product_category'])\n",
    "gender_cols = enc_gender.get_feature_names_out(['gender'])\n",
    "state_cols = enc_state.get_feature_names_out(['address_state'])\n",
    "hour_cols = enc_hour.get_feature_names_out(['hour'])\n",
    "\n",
    "# Create DataFrames from encoded arrays\n",
    "product_df = pd.DataFrame(product_encoded, columns=product_cols, index=X_final_test.index)\n",
    "gender_df = pd.DataFrame(gender_encoded, columns=gender_cols, index=X_final_test.index)\n",
    "state_df = pd.DataFrame(state_encoded, columns=state_cols, index=X_final_test.index)\n",
    "hour_df = pd.DataFrame(hour_encoded, columns=hour_cols, index=X_final_test.index)\n",
    "\n",
    "# Drop original columns and concatenate encoded ones\n",
    "X_final_test = X_final_test.drop(['product_category', 'gender', 'address_state', 'time'], axis=1)\n",
    "X_final_test = pd.concat([X_final_test, product_df, gender_df, state_df], axis=1)\n",
    "X_final_test = pd.concat([hour_df, product_df, gender_df, X_final_test[\"amount\"].to_frame()], axis=1) # only hour, product_category, amount\n",
    "print(X_final_test.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433a534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Predictions on Test Data\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# Get predictions on training data\n",
    "if True:\n",
    "  y_pred_proba = model.predict_proba(X_final_test)[:, 1]\n",
    "  threshold = 0.3  # Set your custom threshold here\n",
    "  y_pred = y_pred_proba >= threshold\n",
    "else:\n",
    "  y_pred = model.predict(X_final_test)\n",
    "\n",
    "print(pd.crosstab(y_final_test, y_pred, rownames=['Actual'], colnames=['Predicted']))\n",
    "\n",
    "# Calculate metrics\n",
    "recall = recall_score(y_final_test, y_pred)\n",
    "precision = precision_score(y_final_test, y_pred)\n",
    "f1 = f1_score(y_final_test, y_pred)\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
